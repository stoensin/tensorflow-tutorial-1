{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Slim_CNN.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "uqRzgo0N5PKL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S8OtAmGP476G",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1686
        },
        "outputId": "b926c4ed-54a8-4ab3-c506-52703d670bb8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532245631656,
          "user_tz": -480,
          "elapsed": 1013126,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import tensorflow.contrib.slim as slim\n",
        "\n",
        "\n",
        "mnist = input_data.read_data_sets('/tmp/mnist/data',one_hot=True)\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "x = tf.placeholder(tf.float32, shape=[None, 28*28], name='input')\n",
        "y_actual = tf.placeholder(tf.float32, shape=[None, 10], name='label')\n",
        "is_training = tf.placeholder(tf.bool, name='is_training')\n",
        "\n",
        "def convnet(inputs, is_training, scope='Convnet'):\n",
        "    with tf.variable_scope(scope, 'Convnet'):\n",
        "        inputs= tf.reshape(inputs, [-1,28,28,1])\n",
        "        # First Group: Convolution + Pooling 28x28x1 => 28x28x20 => 14x14x20\n",
        "        net = slim.conv2d(inputs, 20, [5, 5], padding='SAME', scope='layer1-conv')\n",
        "        net = slim.max_pool2d(net, 2, stride=2, scope='layer2-max-pool')\n",
        "\n",
        "        # Second Group: Convolution + Pooling 14x14x20 => 10x10x40 => 5x5x40\n",
        "        net = slim.conv2d(net, 40, [5, 5], padding='VALID', scope='layer3-conv')\n",
        "        net = slim.max_pool2d(net, 2, stride=2, scope='layer4-max-pool')\n",
        "\n",
        "        # Reshape: 5x5x40 => 1000x1\n",
        "        net = slim.flatten(net)\n",
        "\n",
        "        # Fully Connected Layer: 1000x1 => 1000x1\n",
        "        net = slim.fully_connected(net, 1000, scope='layer5')\n",
        "        net = slim.dropout(net,keep_prob=0.5, is_training=is_training, scope='layer5-dropout')\n",
        "\n",
        "        # Second Fully Connected: 1000x1 => 1000x1\n",
        "        net = slim.fully_connected(net, 1000, scope='layer6')\n",
        "        net = slim.dropout(net,keep_prob=0.5, is_training=is_training, scope='layer6-dropout')\n",
        "\n",
        "        # Output Layer: 1000x1 => 10x1\n",
        "        net = slim.fully_connected(net, 10, scope='output')\n",
        "        net = slim.dropout(net,keep_prob=0.5, is_training=is_training, scope='output-dropout')\n",
        "\n",
        "        return net\n",
        "\n",
        "logits = convnet(x, is_training, scope='Covnet')\n",
        "\n",
        "with tf.name_scope('Loss'):\n",
        "\tcross_entropy =  slim.losses.softmax_cross_entropy(logits, y_actual)\n",
        "with tf.name_scope('Prediction'):\n",
        "\tcorrect_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y_actual, 1))\n",
        "\taccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "with tf.name_scope('Optimizer'):\n",
        "    train_step = tf.train.MomentumOptimizer(0.03,0.5).minimize(cross_entropy)\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "val_data = {\n",
        "    x: mnist.validation.images,\n",
        "    y_actual: mnist.validation.labels,\n",
        "    is_training: False\n",
        "}\n",
        "\n",
        "for i in range(5000):\n",
        "    images, labels = mnist.train.next_batch(100)\n",
        "    sess.run(train_step, feed_dict={x: images, y_actual: labels, is_training: True})\n",
        "    \n",
        "    if i % 100 == 0:\n",
        "        acc = sess.run( accuracy, feed_dict= val_data)\n",
        "        print(\"Step: %5d,CV Accuracy = %5.2f%%\" % (i, acc * 100))\n",
        "\n",
        "test_data = {\n",
        "    x: mnist.test.images,\n",
        "    y_actual: mnist.test.labels,\n",
        "    is_training: False\n",
        "}\n",
        "\n",
        "acc = sess.run(accuracy, feed_dict= test_data)\n",
        "\n",
        "print(\"Test Accuracy is %5.2f%%\" % (100 * acc))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-aba516f534d7>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/mnist/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/mnist/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From <ipython-input-1-aba516f534d7>:45: softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:398: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:399: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.compute_weighted_loss instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:147: add_arg_scope.<locals>.func_with_args (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.add_loss instead.\n",
            "Step:     0,CV Accuracy = 12.46%\n",
            "Step:   100,CV Accuracy = 69.62%\n",
            "Step:   200,CV Accuracy = 91.12%\n",
            "Step:   300,CV Accuracy = 94.34%\n",
            "Step:   400,CV Accuracy = 95.30%\n",
            "Step:   500,CV Accuracy = 95.70%\n",
            "Step:   600,CV Accuracy = 96.46%\n",
            "Step:   700,CV Accuracy = 96.98%\n",
            "Step:   800,CV Accuracy = 97.12%\n",
            "Step:   900,CV Accuracy = 96.90%\n",
            "Step:  1000,CV Accuracy = 97.56%\n",
            "Step:  1100,CV Accuracy = 97.62%\n",
            "Step:  1200,CV Accuracy = 97.46%\n",
            "Step:  1300,CV Accuracy = 97.72%\n",
            "Step:  1400,CV Accuracy = 97.72%\n",
            "Step:  1500,CV Accuracy = 97.74%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step:  1600,CV Accuracy = 97.58%\n",
            "Step:  1700,CV Accuracy = 97.84%\n",
            "Step:  1800,CV Accuracy = 98.04%\n",
            "Step:  1900,CV Accuracy = 97.96%\n",
            "Step:  2000,CV Accuracy = 98.12%\n",
            "Step:  2100,CV Accuracy = 98.10%\n",
            "Step:  2200,CV Accuracy = 98.34%\n",
            "Step:  2300,CV Accuracy = 98.04%\n",
            "Step:  2400,CV Accuracy = 98.40%\n",
            "Step:  2500,CV Accuracy = 98.42%\n",
            "Step:  2600,CV Accuracy = 98.32%\n",
            "Step:  2700,CV Accuracy = 98.54%\n",
            "Step:  2800,CV Accuracy = 98.58%\n",
            "Step:  2900,CV Accuracy = 98.56%\n",
            "Step:  3000,CV Accuracy = 98.60%\n",
            "Step:  3100,CV Accuracy = 98.66%\n",
            "Step:  3200,CV Accuracy = 98.48%\n",
            "Step:  3300,CV Accuracy = 98.42%\n",
            "Step:  3400,CV Accuracy = 98.60%\n",
            "Step:  3500,CV Accuracy = 98.74%\n",
            "Step:  3600,CV Accuracy = 98.74%\n",
            "Step:  3700,CV Accuracy = 98.74%\n",
            "Step:  3800,CV Accuracy = 98.74%\n",
            "Step:  3900,CV Accuracy = 98.74%\n",
            "Step:  4000,CV Accuracy = 98.80%\n",
            "Step:  4100,CV Accuracy = 98.68%\n",
            "Step:  4200,CV Accuracy = 98.82%\n",
            "Step:  4300,CV Accuracy = 98.80%\n",
            "Step:  4400,CV Accuracy = 98.84%\n",
            "Step:  4500,CV Accuracy = 98.76%\n",
            "Step:  4600,CV Accuracy = 98.92%\n",
            "Step:  4700,CV Accuracy = 98.98%\n",
            "Step:  4800,CV Accuracy = 98.76%\n",
            "Step:  4900,CV Accuracy = 98.86%\n",
            "Test Accuracy is 98.89%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
